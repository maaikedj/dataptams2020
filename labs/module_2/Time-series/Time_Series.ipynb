{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "H-4qN7md4iRL"
   },
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "FZTfRX-O42mK"
   },
   "source": [
    "## Introduction \n",
    "\n",
    "So far we have studied data that is static in time. This was important since many models require that we assume that observations are independent of one another. However, when dealing with time ordered data, many times this assumption is no longer valid. For example, the temperature observed today is not independent of the temperature yesterday. Another example is the stock market. Today's stock prices are related to yesterday's stock prices. In this lesson we will explore how to deal with data that contains such relationships\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "n64b7pQy45_y"
   },
   "source": [
    "## Time Series Decomposition\n",
    "\n",
    "One of the ways to overcome the issues caused by having a relationship between the observations is to decompose the data into components. Typically, we split the data into two types of components - **systematic** and **non-systematic.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "uFTlf4fj5CTf"
   },
   "source": [
    "\n",
    "*   Systematic components are components that can have consistency or recurrence.\n",
    "*   Non-systematic components cannot be modeled.\n",
    "\n",
    "We can typically decompose a time series into 4 components - 3 systematic components and one noise component.:\n",
    "\n",
    "1.  Observed (mean) value of the series (i.e. the average value);\n",
    "2.  The trend of the series - the increase and decrease in values;\n",
    "3.  The seasonality or the cyclical pattern of the series (e.g. sales of summer clothing drops during the winter);\n",
    "4.  The noise is typically the random variation in our data.\n",
    "\n",
    "Written mathematicaly, we can decompose the time series into 3 systematic componants as follows:\n",
    "\n",
    "$$y_{t} = T_{t} + S_{t} + R_{t} + \\epsilon_{t}.$$\n",
    "\n",
    "Thus, the value at $t$ for $y$ consists of $S$, seasonality, $T$, the trend and $R$, the residual. Note that the residuals is the value that is left once we remove trend and seasonality. In complex time series analysis it may be useful, but we will not pursue it any further. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "47eDotSkfPaY"
   },
   "source": [
    "#### Example: The Trend\n",
    "\n",
    "The trend of a time series looks like this:\n",
    "\n",
    "![alt text](https://otexts.com/fpp2/fpp_files/figure-html/elecequip-trend-1.png)\n",
    "\n",
    "It simply shows the overall movement of the time series, thereby disregarding seasonality or major fluctuations (anomalies). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "694Rl1ZE5XId"
   },
   "source": [
    "### Example: Time Series Decomposition in Python\n",
    "\n",
    "We will focus on the statsmodels library for modeling and plotting time series data in Python. statsmodels contains a function called seasonal_decompose that will allow us to plot the decomposed time series data.\n",
    "\n",
    "For our example, we will use the occupancy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "lZheOLj65yGb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 677,
     "status": "ok",
     "timestamp": 1587198263119,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "2OTBu2cG4f-m",
    "outputId": "58064890-90df-47a8-ee5f-ec3a0fee2617"
   },
   "outputs": [],
   "source": [
    "occupancy = pd.read_csv('https://raw.githubusercontent.com/loukjsmalbil/datasets_ws/master/occupancy.csv')\n",
    "occupancy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "PVUGiZ3950dv"
   },
   "source": [
    "To plot this data, we must make sure our index is a time series with a known frequency. To analyze time series data, the data needs to be equally spaced. In the code below, we will change the type of the date column to datetime and change the index to the date column. Our frequency is 1 hour. Even though we can see that the difference between observation is 1 hour, it is not inferred, and we need to specify it ourselves. To read more about frequencies, look here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 745,
     "status": "ok",
     "timestamp": 1587198391604,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "nuPeyhkD5zjh",
    "outputId": "59a3157f-a271-42ac-a2b6-602f5218be9f"
   },
   "outputs": [],
   "source": [
    "occupancy.date = pd.to_datetime(occupancy.date)\n",
    "occupancy.index = pd.DatetimeIndex(occupancy.date, freq='H')\n",
    "occupancy.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "RAtLpyeX56jp"
   },
   "source": [
    "Now we can plot the decomposed time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "U_D6bNz_53Nk"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1924,
     "status": "ok",
     "timestamp": 1587198454560,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "BALYqghd59WU",
    "outputId": "28429a21-216f-4a2e-8c41-332986b668e6"
   },
   "outputs": [],
   "source": [
    "res = sm.tsa.seasonal_decompose(occupancy.CO2)\n",
    "resplot = res.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "H65N_yT9_JXx"
   },
   "source": [
    "Let us make a plot that is easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "Ydbc3B3bcI6I"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1678,
     "status": "ok",
     "timestamp": 1587198467931,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "I7gixz7Tb_x_",
    "outputId": "65251916-3fae-4ef0-956d-b28e3fea269e"
   },
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3, ax4) = plt.subplots(4,1, figsize=(15,8))\n",
    "res.observed.plot(ax=ax1)\n",
    "res.trend.plot(ax=ax2)\n",
    "res.seasonal.plot(ax=ax3)\n",
    "res.resid.plot(ax=ax4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "WbMoLhBmgooH"
   },
   "source": [
    "In our decomposition, we have the 'raw data' on top. The second subplot shows the overall trend our data follows. The third subplot is our seasonal decomposition. As can be seen, there is no variation over the various months, indicating that seasonality does not play a major role in CO2 measurments. The last plot is simply the series that 'remains' after we subtracted the seasonality component and the trend. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "bJU0BG9w6FwD"
   },
   "source": [
    "## Autoregression\n",
    "\n",
    "**An autoregressive model is a model that uses previous observations in the time series to predict the next value in the model.** In previous lessons, we have looked at linear models where the response variable depends only on the predictor variables and the linear regression equation is of the form:\n",
    "\n",
    "$$Y = \\beta_{0} + \\beta_{1} X_{1} + ... \\beta_{n} X_{n}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "MJhdTtv-6WP9"
   },
   "source": [
    "However, when working with time series data, our response variable depends not only on the predictor variables but also on the response variable itself. **A variable that depends on itself is called an autocorrelated variable.**  More information about autocorrelation can be found [here](https://www.investopedia.com/terms/a/autocorrelation.asp). Typically, our regression equation will be of the form below. We can model an autoregressive relation using an **autoregressive model (AR)**. In an autoregressive model we have a variable whose value only on the previous time period.\n",
    "\n",
    "$$y_{t} = \\beta_{0} + \\beta_{1} y_{t-1},$$\n",
    "\n",
    "where $\\beta_{0}$ is essentially some constant (the starting point-value of $y_{t}$ and $\\beta_{1}$ the factor by which the previous value of $y$, $y_{t-1}$, is multiplied. \n",
    "\n",
    "Our model can also depend on more than one time period in the past. In that case, we say that we have a higher **order**. For instance, \n",
    "\n",
    "$$y_{t} = \\beta_{0} + \\beta_{1} y_{t-1} + \\beta_{2} y_{t-2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "BzLM5N-V6h9M"
   },
   "source": [
    "## Checking for Autocorrelation\n",
    "\n",
    "We can check for autocorrelation in our data using a lag plot. **This plot will plot $y_{t}$ against $y_{t-1}$. Pandas has a function called lag_plot for detecting these relationships.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "l7wgK3FX6lRV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import lag_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1587199441388,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "LPhJ8AGk5-Hj",
    "outputId": "1d58acce-cab2-4f4f-f1c4-c17ea86e4433"
   },
   "outputs": [],
   "source": [
    "lag_plot(occupancy.CO2, lag=1)        #try with 1, 2, 3, 53 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "rtCu71uU6yeI"
   },
   "source": [
    "A line along the diagonal shows that there is an autoregressive relationship.\n",
    "\n",
    "To create an **autoregressive model we use the AR function.** Typically, we note an autoregressive model with the notation **AR(n) where n is the number of lag periods.** In the example below, we will create an autoregressive model with lag 1 to model the rate of CO2. Why a lag of 1? Well, let's make a plot to show why.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "63M2DaawBR9j"
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1587199519430,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "du9VK_FhBWB-",
    "outputId": "955319db-8a3d-423a-8916-3da814014a4c"
   },
   "outputs": [],
   "source": [
    "# Partial Autocorrelation for the first 50 lags \n",
    "# y-axis (-1 to 1) shows autocorrelation-value vs. x-axis lag \n",
    "plot_pacf(occupancy.CO2, lags=50)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "eqGbptDDBQ8J"
   },
   "source": [
    "\n",
    "**Note that we split the data into test and train and always use the last few observations when working with time series data. We do this to ensure that the model gives good predictions even on data it has not seen. Since the data is ordered, we cannot select the test data at random.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "UJzNY1Em6re8"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "8nFO0U6TRMqd"
   },
   "outputs": [],
   "source": [
    "train, test = occupancy.CO2[:-10], occupancy.CO2[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1587199940087,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "A31ipajCUQCD",
    "outputId": "b9db6604-d9a1-42f5-b097-beab1eb201f4"
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1587199953739,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "4jNLQBgdfUFN",
    "outputId": "59a2f836-4aee-49f8-b02b-90ca9b3a8cb8"
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "KG83pvFrRPb3"
   },
   "outputs": [],
   "source": [
    "model = AR(occupancy.CO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "UKMIC4UzRS1s"
   },
   "outputs": [],
   "source": [
    "model_fit = model.fit(maxlag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "Lj7u7iIRRV7g"
   },
   "outputs": [],
   "source": [
    "predictions = model_fit.predict(start=len(train), end=len(train)+len(test)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1587200036006,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "VNTlOg3X69GO",
    "outputId": "a30256d8-1a47-4f54-8821-801c0748e753"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'observed':test, 'predicted':predictions})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "P3tngTiA66XR"
   },
   "source": [
    "## Stationarity \n",
    "\n",
    "**A time series is considered stationary if its mean and/or variance do not vary over time. As such, we assume that its mean and variance do not change over time, but stay constant.** When we have a stationary time series we may be able to infer some properties of the series that are *not dependent * upon the time of observation. As such, if we have seasonality or a clear trend over time, the time series is non-stationary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "fJMIISzPjgTp"
   },
   "source": [
    "\n",
    "To check whether we have a stationary time series, we can either examine the decomposition plot visually, compute the mean and standard deviation over time, or use statistical tests. One possible test is the **Augmented Dickey-Fuller test.** This test has the following hypothesis:\n",
    "\n",
    "\n",
    "\n",
    "*   $H0$: Data is not stationary\n",
    "*   $H1$: Data is stationary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "1a5lcMPt7Rls"
   },
   "source": [
    "We test stationarity using the adrfuller function in statsmodels. The example below demonstrates this with our CO2 data. The adrfuller function returns multiple values. The second position in the data structure returned is the p-value of our hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "Ydu3pJct7R9n"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 970,
     "status": "ok",
     "timestamp": 1587200404756,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "7FayMKBM7VMp",
    "outputId": "58fa85be-863d-4dfa-c716-31d55e2e059b"
   },
   "outputs": [],
   "source": [
    "adfuller(occupancy.CO2)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "vRjywTue7ZL3"
   },
   "source": [
    "The p-value is greater than 0.05. Therefore, with a 95% confidence interval, we do not reject the null hypothesis and conclude that the data is not stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "2NFPgemDjuE2"
   },
   "source": [
    "### Mini-Quiz!\n",
    "\n",
    "Which one of these time series is/are stationary?\n",
    "\n",
    "![alt text](https://otexts.com/fpp2/fpp_files/figure-html/stationary-1.png)\n",
    "\n",
    "Figure 8.1: Which of these series are stationary? (a) Google stock price for 200 consecutive days; (b) Daily change in the Google stock price for 200 consecutive days; (c) Annual number of strikes in the US; (d) Monthly sales of new one-family houses sold in the US; (e) Annual price of a dozen eggs in the US (constant dollars); (f) Monthly total of pigs slaughtered in Victoria, Australia; (g) Annual total of lynx trapped in the McKenzie River district of north-west Canada; (h) Monthly Australian beer production; (i) Monthly Australian electricity production. (Retrieved From This [Resource](https://otexts.com/fpp2/stationarity.html))\n",
    "\n",
    "\"#@title\n",
    "Obvious seasonality rules out series (d), (h) and (i). Trends and changing levels rules out series (a), (c), (e), (f) and (i). Increasing variance also rules out (i). That leaves only (b) and (g) as stationary series.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "XZnltRE47dbH"
   },
   "source": [
    "## Random Walks\n",
    "\n",
    "A random walk is a type of time series model where each observation depends on the sum of the previous observation and a random noise component. The formal notation for this is:\n",
    "\n",
    "$$y_{t} = y_{t-1} + \\epsilon_{t},$$\n",
    "\n",
    "where $\\epsilon_{t}$ denotes a random noise variable with $\\epsilon_{t} \\sim \\mathcal{N}(0,1).$\n",
    "\n",
    "Random walks are considered **non-stationary** because and therefore **time dependent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "_sQQ2efs7wre"
   },
   "source": [
    "## Moving Average\n",
    "\n",
    "Moving average models are similar to autoregressive models. Moving average models also depend on a linear combination of past data. **However, unlike autoregressive models, these models depend on past white noise terms.** While the name is the same, moving average models are not the same as calculating the moving average of a time series.\n",
    "\n",
    "Moving average models are typically noted with **MA(q) where q is the number of past white noise terms summed by the model.** For example, a first order moving average model, MA(1) will be denoted by:\n",
    "\n",
    "$$y_{t} = \\mu  + \\theta_{t} \\epsilon_{t-1} +  \\epsilon_{t},$$\n",
    "\n",
    "where $\\mu$ denotes the mean of the time series, $\\epsilon_{t}$ is the error term and $\\theta$ the model parameter. \n",
    "\n",
    "We may also have a **AM(2)** model, where we take into account two lags or time steps: \n",
    "\n",
    "$$y_{t} = \\mu + \\theta_{1} \\epsilon_{t-1} + \\theta_{2}\\epsilon_{t-2} + \\epsilon_{t}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "Ntz1qFeIDXNH"
   },
   "source": [
    "Let us have a look at two MA models. The first model, MA(1) denotes:\n",
    "\n",
    "$$y_{t} = 20 + \\epsilon + 0.8 \\epsilon_{t-1}.$$\n",
    "\n",
    "The second one, MA(2), displays the following model:\n",
    "\n",
    "$$y_{t} = \\epsilon_{t} + \\epsilon_{t-1} + 0.8 \\epsilon_{t-2}.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "UoMwNk8fEHYL"
   },
   "source": [
    "\n",
    "![alt text](https://otexts.com/fpp2/fpp_files/figure-html/maq-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "JXJ1WvUxCv7P"
   },
   "source": [
    "## ARMA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "6KfIBkIw7OOy"
   },
   "source": [
    "\n",
    "We can create a moving average model using the **ARMA (AutoRegressive Moving Average)** function in the statsmodels package. This function generates models that can have both an autoregressive component as well as a moving average component. \n",
    "\n",
    "Mathematically, for a ARMA(1,1) model, we have the following:\n",
    "\n",
    "$$y_{t} = \\beta_{0} + \\beta_{1} y_{t-1} + \\theta_{1}\\epsilon_{t-1} + \\epsilon_{t}.$$\n",
    "\n",
    "However, here we will set the autoregressive lag to zero to create only a moving average model. Let's use our CO2 data again for this example.\n",
    "\n",
    "Recall that $\\beta_{0} + \\beta_{1} y_{t-1}$ represents the *AR* part of the equation and $\\theta_{1}\\epsilon_{t-1} + \\epsilon_{t}$ the *MA* part of the model. As such, we have a combination of a AR(1) and a MA(1) model, which we combined into a ARMA(1,1) model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "tY63UNEb7XT_"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "HqetjhZn8Ist"
   },
   "outputs": [],
   "source": [
    "model = ARMA(occupancy.CO2, order=(0, 1))       #AR = 0, MA=1  \n",
    "model_fit = model.fit()\n",
    "predictions = model_fit.predict(start = len(occupancy.CO2)-3, end = len(occupancy.CO2)-1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "t5OOC_Uf8MpH"
   },
   "source": [
    "Let's look at the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1587201687796,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "9Dd1Ccx_8Kur",
    "outputId": "44309532-7d1c-45cf-9cad-9fdaa08693d5"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'observed':occupancy.CO2[-3:], 'predicted':predictions})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "LFQtvAIg8Skm"
   },
   "source": [
    "We can see that this model alone is not a great fit for this data since there is a big difference between observed and predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "pZ3GzRvd8TXl"
   },
   "source": [
    "## Combining Autoregression with Moving Average\n",
    "\n",
    "As we have seen in the previous paragraph, we can create a model with both an autoregressive component and a moving average component. This model is called an ARMA model and is denoted by ARMA(n, q) where n is the number of lag periods and q is the number of past white noise terms. Below is an example of an ARMA model with two lag terms and one white noise term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "LnX9pwZgS8Ox"
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "model = ARMA(occupancy.CO2, order=(2, 1))      # AR 2, MA 1\n",
    "model_fit = model.fit(disp=False)\n",
    "# make prediction\n",
    "predictions = model_fit.predict(len(occupancy.CO2)-3, len(occupancy.CO2)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "-k-l0cTPTAmv"
   },
   "source": [
    "We expect our predictions to improve:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1409,
     "status": "ok",
     "timestamp": 1587201982853,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "O9lyH5rjTBGg",
    "outputId": "11ebc5fd-5368-41f1-c8b1-b1b3445aba03"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'observed':occupancy.CO2[-3:], 'predicted':predictions})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "9lkIfRYR8kes"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this lesson we were introduced to a number of basic concepts in time series modeling. Time series models require different treatment than linear models. We learned about the different components of a time series and how to plot them. We learned about stationarity, random walks, and autoregressive and moving average models. This introduction should provide you with the tools to evaluate and model time ordered data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "n3r1sqcMiLKQ"
   },
   "source": [
    "Some useful resources:\n",
    "\n",
    "\n",
    "\n",
    "*   [Here](https://otexts.com/fpp2/moving-averages.html)\n",
    "*   [Here](https://otexts.com/fpp2/stationarity.html)  \n",
    "*   [Here](https://www.youtube.com/watch?v=oY-j2Wof51c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "V2UBVA_X8mpm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO8zUUNVcR/XFTw2PhwRQ8l",
   "collapsed_sections": [],
   "name": "Time_Series.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
