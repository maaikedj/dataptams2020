{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoodReads to BetterReads\n",
    "\n",
    "by: Sara Mendoza\n",
    "\n",
    "Data Analytics - Ironhack Amsterdam / cohort Jan - June 2020\n",
    "\n",
    "Project 6 - June 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "\n",
    "In this notebook I clean and inspect the data that was used from the GoodReads website through the file \"1_GoodReads_API\". This data will be used to create a program that recommends books based on similar users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necesary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the downloaded data\n",
    "df1 = pd.read_csv('../data/goodreads_batch1.csv')\n",
    "df2 = pd.read_csv('../data/goodreads_batch2.csv')\n",
    "print(df1.shape,df2.shape)\n",
    "\n",
    "#and concatenating in one file\n",
    "df = pd.concat([df1,df2])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Inspecting the data\n",
    "We want to make sure that all the data is clean and ready to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types are correct\n",
    "print(df.dtypes)\n",
    "\n",
    "# we have a total of 66,055 lines of data\n",
    "print(df.shape)\n",
    "\n",
    "# 2,383 different users / out of over 6,000 users tried!\n",
    "print(len(df['userid'].unique()))\n",
    "\n",
    "# with a mean of 28 books per user\n",
    "print(df['userid'].value_counts().mean())\n",
    "\n",
    "# 33,932 different books\n",
    "print(len(df['book'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking The rating distribution for our data we see there is quite a lot of books with rating zero, so no rating at all.\n",
    "But mostly books are rated 4 or 5 stars, probably because poeple like to add to their lists books they liked and not books they disliked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'].value_counts(sort=False).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at what our highest rated books are all-round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check to see what are our highest rated books\n",
    "mean_rating = df.pivot_table(index=['book'],values=['rating'],aggfunc=(len,np.mean)).reset_index()\n",
    "mean_rating.columns = ['_'.join(col).strip() for col in mean_rating.columns.values]\n",
    "\n",
    "# most books have been rated few times, to see the most popular books we will drop everything will less than 10 ratings\n",
    "mean_rating['rating_len'].value_counts()\n",
    "mean_rating = mean_rating.loc[mean_rating.rating_len > 10]\n",
    "mean_rating['rating_len'].value_counts()\n",
    "\n",
    "# below the 5 highest rates books in our data set\n",
    "mean_rating.sort_values(by='rating_mean', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above list shows the rating mean, but these books probably also have less ratings than other books, so its not a accurate depiction of the most liked books.\n",
    "\n",
    "Since we want the information of the books people have enjoyed reading, we will remove all lines with less than 4 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping books with scores of 4 or 5 stars, as we want the books that are recommended\n",
    "high_rated = df.loc[df.rating > 3]\n",
    "\n",
    "# Now we have a total of 40,163 lines of data\n",
    "print(high_rated.shape)\n",
    "\n",
    "# 1674 different users\n",
    "print(len(high_rated['userid'].unique()))\n",
    "\n",
    "# with a mean of 23 books per user\n",
    "print(high_rated['userid'].value_counts().mean())\n",
    "\n",
    "# and a total of 21,369 different books\n",
    "print(len(high_rated['book'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check, out of all the books that are rated 4 or 5 stars, which ones have been rated 4 or 5 the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high_rated.groupby('book')['rating'].count()\n",
    "\n",
    "most_rated = high_rated.pivot_table(index=['book'],values=['rating'],aggfunc=(len,np.mean)).reset_index()\n",
    "most_rated.columns = ['_'.join(col).strip() for col in most_rated.columns.values]\n",
    "most_rated.sort_values(by='rating_len', ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and this top 20 list full of bestsellers is exactly why I want to build a recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # first we create a matrix of all books vs all users, if they have not read / rated it, the rating will be nan\n",
    "# high_rated_pivot = high_rated.pivot_table(index='book', columns='userid').rating.reset_index()\n",
    "\n",
    "# #searching my own book to check that the correct rating is reflecting\n",
    "# high_rated_pivot.loc[high_rated_pivot.book == 'Normal People'][42889636]\n",
    "# # I indeed rated Normal People with 4 stars\n",
    "\n",
    "# high_rated_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # matrix of total books recommended per user\n",
    "# books_loved = pd.DataFrame(high_rated.groupby('userid')['rating'].count())\n",
    "# books_loved.rename(columns={'rating': 'total_loved_books'},inplace=True)\n",
    "# books_loved.sort_values('total_loved_books', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now I want to check which users are highly correlated, to find book recommendations\n",
    "# corr = high_rated_pivot.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #selecting only one user, to find similar users\n",
    "# my_user = 42889636\n",
    "# similar_to_mine = corr[my_user]\n",
    "# similar_to_minedf = pd.DataFrame(similar_to_mine)\n",
    "# similar_to_minedf.rename(columns={my_user: 'pearson_corr'},inplace=True)\n",
    "# similar_to_minedf.dropna(inplace=True)\n",
    "\n",
    "# #adding information of how many books other users have loved\n",
    "# similar_to_minedf = similar_to_minedf.join(books_loved['total_loved_books'])\n",
    "\n",
    "# #other users need to at least have loved half the books I have loved to be able to recommend\n",
    "# parameter = books_loved.reset_index()\n",
    "# parameter = parameter.loc[parameter['userid'] == my_user]['total_loved_books'] / 2\n",
    "# parameter\n",
    "\n",
    "# top = similar_to_minedf[similar_to_minedf['total_loved_books'] >= int(parameter)].drop(my_user).sort_values('pearson_corr', ascending=False).head(20)\n",
    "# top.reset_index(inplace=True)\n",
    "# top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_id = list(top['userid'])\n",
    "\n",
    "# #adding my user to identify the books I've already read\n",
    "# top_id.append(my_user)\n",
    "# top_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #high_rated_pivot#[top_ten_id].dropna(how='all')\n",
    "\n",
    "# # now we create a new matrix will all the books that have been read by the highest corr users\n",
    "# top_books = high_rated.pivot_table(index='userid', columns='book').rating.reset_index()\n",
    "# top_books = top_books[top_books['userid'].isin(top_id)].dropna(how='all',axis=1)\n",
    "\n",
    "# # but we drop all books that the user has already read\n",
    "# read_books = top_books[(top_books['userid'] == my_user)].dropna(axis=1).columns[1:]\n",
    "# read_books = list(df[(df['userid'] == my_user)]['book'])\n",
    "# for i in read_books:\n",
    "#     if i in top_books.columns:\n",
    "#         top_books.drop(i,1,inplace=True)\n",
    "\n",
    "# # top_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "# # recommendation given\n",
    "# recommendation = top_books.fillna(0).astype(bool).sum(axis=0).sort_values(ascending=False).head(20)\n",
    "# recommendation.reset_index()[1:].rename(columns={0: 'times recommended'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove top 20 liked books in general ?\n",
    "# # remove harry potter, hunger games, A Game of Thrones\n",
    "# read_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_rated['userid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from goodreads import client\n",
    "# gc = client.GoodreadsClient('wxwrc6aLfRoMX3Ivr784A','rFT6Ytzh5TRBNcWnAYTdWY1wU5U27fQ6tEegWiSM5M')\n",
    "\n",
    "\n",
    "# #             list_users.append((i,user.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/goodreads_batch1.csv')\n",
    "df2 = pd.read_csv('../data/goodreads_batch2.csv')\n",
    "df = pd.concat([df1,df2])\n",
    "\n",
    "# Only keeping books with scores of 4 or 5 stars, as we want the books that are recommended\n",
    "high_rated = df.loc[df.rating > 3]\n",
    "high_rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rating = high_rated.pivot_table(index=['book'],values=['rating'],aggfunc=(len,np.mean)).reset_index()\n",
    "mean_rating.columns = ['_'.join(col).strip() for col in mean_rating.columns.values]\n",
    "best_sellers = mean_rating.sort_values(by='rating_len', ascending=False)[0:20]\n",
    "best_sellers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rating = high_rated.pivot_table(index=['book'],values=['rating'],aggfunc=(len,np.mean)).reset_index()\n",
    "mean_rating.columns = ['_'.join(col).strip() for col in mean_rating.columns.values]\n",
    "best_sellers = mean_rating.sort_values(by='rating_len', ascending=False)[0:20]\n",
    "best_sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
