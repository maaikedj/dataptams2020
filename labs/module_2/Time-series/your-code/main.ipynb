{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources (README.md file)\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Import numpy and pandas\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Challenge 1 - Loading and Evaluating The Data\n",
    "\n",
    "In this lab, we will look at a dataset of sensor data from a cellular phone. The phone was carried in the subject's pocket for a few minutes while they walked around. As usual, download the file from [here](https://drive.google.com/file/d/1G44c7-GImWpFjiQ0bctRNJXKus_WTOlx/view?usp=sharing) and \n",
    "place it in the provided data folder.\n",
    "\n",
    "To load the data, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Load the file sub_1.csv and drop the \"Unnamed column\" Run this code:\n",
    "\n",
    "sensor = pd.read_csv('../data/sub_1.csv')\n",
    "sensor.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Examine the data using the `head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "sensor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Check whether there is any missing data. If there is any missing data, remove the rows containing missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "sensor.isnull().sum()\n",
    "\n",
    "# there is no missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "How many rows and columns are in our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "sensor.shape\n",
    "\n",
    "# 12 columns, 1751 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "To perform time series analysis on the data, we must change the index from a range index to a time series index. In the cell below, create a time series index using the `pd.date_range` function. Create a time series index starting at 1/1/2018 00:00:00 and ending at 1/1/2018 00:29:10. The number of periods is equal to the number of rows in `sensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "time_index = pd.date_range(start = '1-1-2018 00:00:00', end = '1-1-2018 00:29:10', periods = 1751)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Assign the time series index to the dataframe's index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "sensor.set_index(time_index, inplace = True)\n",
    "\n",
    "sensor.head()\n",
    "#Paolo:yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Our next step is to decompose the time series and evaluate the patterns in the data. Load the `statsmodels.api` submodule and plot the decomposed plot of `userAcceleration.x`. Set `freq=60` in the `seasonal_decompose` function. Your graph should look like the one below.\n",
    "\n",
    "[time series decomposition](https://drive.google.com/file/d/1tiOAggkGBE7ZzQ0QaOj4jMpZ4AJ4cGp1/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "res = sm.tsa.seasonal_decompose(sensor['userAcceleration.x'], period = 60)\n",
    "resplot = res.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Plot the decomposed time series of `rotationRate.x` also with a frequency of 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "res = sm.tsa.seasonal_decompose(sensor['rotationRate.x'], period = 60)\n",
    "resplot = res.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Challenge 2 - Modelling the Data\n",
    "\n",
    "To model our data, we should look at a few assumptions. First, let's plot the `lag_plot` to detect any autocorrelation. Do this for `userAcceleration.x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "from pandas.plotting import lag_plot\n",
    "lag_plot(sensor['userAcceleration.x'], lag = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Create a lag plot for `rotationRate.x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "lag_plot(sensor['rotationRate.x'], lag = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "What are your conclusions from both visualizations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your conclusions here:\n",
    "\n",
    "# There seems to be autocorrelation between time points for both variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The next step will be to test both variables for stationarity. Perform the Augmented Dickey Fuller test on both variables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# for userAcceleration.x:\n",
    "\n",
    "adfuller(sensor['userAcceleration.x'])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# for rotationRate.x:\n",
    "\n",
    "adfuller(sensor['rotationRate.x'])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "What are your conclusions from this test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your conclusions here:\n",
    "\n",
    "# I conclude that both variables are stationary over time, because the p-values are (much) smaller 0.05\n",
    "#Paolo:yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Finally, we'll create an ARMA model for `userAcceleration.x`. Load the `ARMA` function from `statsmodels`. The order of the model is (2, 1). Split the data to train and test. Use the last 10 observations as the test set and all other observations as the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "#Paolo: The model should be made not on all the data, as you do now, but on all the data minus the last 10.\n",
    "# The idea is to train and make predictions on different segments of the data.\n",
    "# This is something we will see better in module3.\n",
    "model = ARMA(sensor['userAcceleration.x'], order=(2, 1)) \n",
    "model_fit = model.fit()\n",
    "predictions = model_fit.predict(start = len(sensor['userAcceleration.x'])-  10, end = len(sensor['userAcceleration.x'])-1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'observed': sensor['userAcceleration.x'][-10:], 'predicted': predictions})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "To compare our predictions with the observed data, we can compute the RMSE (Root Mean Squared Error) from the submodule `statsmodels.tools.eval_measures`. You can read more about this function [here](https://www.statsmodels.org/dev/generated/statsmodels.tools.eval_measures.rmse.html). Compute the RMSE for the last 10 rows of the data by comparing the observed and predicted data for the `userAcceleration.x` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "rmse(df['observed'], df['predicted'], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#Paolo: yes great lab!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
