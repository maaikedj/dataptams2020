{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Embedding, Flatten, Dot\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Engine to connecto to RDS Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "                       .format(user=\"admin\",\n",
    "                               pw=\"}G~j_?DwNLe{|4Q{]#\",\n",
    "                               host=\"database-1.clar7sbwghxi.eu-west-1.rds.amazonaws.com\",\n",
    "                               db=\"recommender\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recover Data from SQL Tables\n",
    "\n",
    "The book_tags and tags queries are commented since they were not used on this iteration of the project due to lack of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_sql_query('SELECT * FROM rating', engine)\n",
    "books = pd.read_sql_query('SELECT * FROM book', engine)\n",
    "# book_tags = pd.read_sql_query('SELECT * FROM books_tags', engine)\n",
    "# tags = pd.read_sql_query('SELECT * FROM tag', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "n_users = len(ratings['user_id'].unique())\n",
    "n_books = len(ratings['book_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we will create vectors, The first chunk says takes a book id as input, and then embed the user into a 5-dimensional space. Flatten it out so that we have a vector.\n",
    " \n",
    " The same goes for the user (by using the user id). \n",
    " \n",
    " The last chunk takes the dot product between these two vectors and produces a single number. We then define the model by saying that we want to take the inputs and output the dot product between their latent embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_input = Input(shape=[1], name=\"Book-Input\")\n",
    "book_embedding = Embedding(n_books+1, 5, name=\"Book-Embedding\")(book_input)\n",
    "book_vec = Flatten(name=\"Flatten-Books\")(book_embedding)\n",
    "\n",
    "user_input = Input(shape=[1], name=\"User-Input\")\n",
    "user_embedding = Embedding(n_users+1, 5, name=\"User-Embedding\")(user_input)\n",
    "user_vec = Flatten(name=\"Flatten-Users\")(user_embedding)\n",
    "\n",
    "prod = Dot(name=\"Dot-Product\", axes=1)([book_vec, user_vec])\n",
    "model = Model([user_input, book_input], prod)\n",
    "model.compile('adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model chosing 10 epochs and verbose mode to evaluate the evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([train['user_id'], train['book_id']], train['rating'], epochs=10, verbose=1)\n",
    "model.save('recommender_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings are weights that are learned to represent some specific variable like books and user in our case and therefore we can not only use them to get good results on our problem but also to extract inside about our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings\n",
    "book_em = model.get_layer('Book-Embedding')\n",
    "book_em_weights = book_em.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(book_em_weights)\n",
    "fig = px.scatter(x=pca_result[:,0], y=pca_result[:,1])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tnse_results = tsne.fit_transform(book_em_weights)\n",
    "fig = px.scatter(x=tnse_results[:,0], y=tnse_results[:,1])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can visualize the improvement of the loss function over the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.Series(history.history['loss'])\n",
    "fig = px.line( x=loss.index, y=loss, title='Loss evolution per epoch', log_y=True)\n",
    "fig.update_xaxes(title_text='Epochs')\n",
    "fig.update_yaxes(title_text='Loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test the accuracy of our model with our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([test['user_id'], test['book_id']])\n",
    "predictions = np.array([a[0] for a in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['predicted rating'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have a fairly accurate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
