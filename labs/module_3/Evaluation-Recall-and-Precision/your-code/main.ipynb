{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "# mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "# X, y = mnist['data'], mnist['target']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, plot_roc_curve, roc_auc_score\n",
    "\n",
    "## NOTICE: IT IS REALLY NECESSARY TO INCLUDE SOME KIND OF REFERAL OR DESCRIPTION OF THE DATABASES WE ARE USING, THE LABS ARE ALREADY VERY DENSE AND DIFFICULT TO DO TO ON TOP ON THAT THROW US ON THE BLIND\n",
    "## TO WORK WITH A DATABASE WE HAVE NOT A CLUE WHAT IT IS ABOUT. IT TOOK ME LIKE 40 MIN JUST TO UNDERSTAND WHAT THE DATABASE IS ABOUT AND THEN BE ABLE TO DO THE EXERCISES SINCE I NOW UNDERSTAND WHAT\n",
    "## IM BEING ASKED TO DO. AND IT IS NOT OBVIOUS THAT THE DESCRIPTION IS ON THE DOWNLOADED VARIABLE.\n",
    "\n",
    "## NOTICE 2: ALSO THE LAB IS OUTDATED, THE MOMENT I RUN THE FIRST LINE IM GETTING AN ERROR. fetch_mldata IS NOT USED ANYMORE AND MUST BE REPLACED BY ANOTHER PACKAGE. THIS ISSUE IS WELL KNOWN FOR A YEAR\n",
    "## AND I WOULD EXPECT TO NOT ENCOUNTER IT IN A LAB.\n",
    "\n",
    "#Paolo: points taken Victor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def sort_by_target(mnist):\n",
    "    reorder_train = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:, 1]\n",
    "    reorder_test = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:, 1]\n",
    "    mnist.data[:60000] = mnist.data[reorder_train]\n",
    "    mnist.target[:60000] = mnist.target[reorder_train]\n",
    "    mnist.data[60000:] = mnist.data[reorder_test + 60000]\n",
    "    mnist.target[60000:] = mnist.target[reorder_test + 60000]\n",
    "\n",
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "    mnist.target = mnist.target.astype(np.int8)\n",
    "    sort_by_target(mnist)\n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Now take a look at the shapes of the X and y matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X[36000]\n",
    "#Paolo:yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "plt.imshow(X[36000].reshape(28,28), cmap = plt.cm.binary, interpolation=\"nearest\")\n",
    "#Paolo:yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X_train = X[:60000]\n",
    "X_test = X[-10000:]\n",
    "y_train = y[:60000]\n",
    "y_test = y[-10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_5 = np.where(y != 5, 0, y)\n",
    "y_5 = np.where(y_5 == 5, 1, y_5)\n",
    "\n",
    "y_5_train = y_5[:60000]\n",
    "y_5_test = y_5[-10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model_5 = LogisticRegression()\n",
    "# model_5.max_iter = 10000\n",
    "model_5.fit(X_train, y_5_train)\n",
    "\n",
    "y_pred = model_5.predict(X)\n",
    "#Paolo: here you could predict on X_train\n",
    "model_5.score(X_test,y_5_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'pred': y_pred, 'val': y_5}).loc[36000]\n",
    "#YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_pred, y_5).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "never_5_clf.fit(X_train, y_5_train)\n",
    "y_predict_dumb = never_5_clf.predict(X)\n",
    "tn, fp, fn, tp = confusion_matrix(y_predict_dumb, y_5).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_predict_dumb, y_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# From a first glance we see that for value 0 (not a number 5) they both work pretty well, but the first one is slighty better. On the second value (1 for number 5) the first model still has a high\n",
    "# value but slower than for 0, while the second model its completely disastrous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(model_5, X_test, y_5_test) \n",
    "plot_roc_curve(never_5_clf, X_test, y_5_test) \n",
    "plt.show()\n",
    "# This gives me an error saying that Never5Classifier is not a binary classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_5, y_predict_dumb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_5, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# The non dumb model works much better. This metric tells us the area under the curve of our model, which translates to the prediction capacity, the higher the area under the curve, the higher\n",
    "# the probability of predicting 1 as 1 and 0 as 0\n",
    "#paolo: great lab!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
