{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "# mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "# X, y = mnist['data'], mnist['target']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, plot_roc_curve, roc_auc_score\n",
    "\n",
    "## NOTICE: IT IS REALLY NECESSARY TO INCLUDE SOME KIND OF REFERAL OR DESCRIPTION OF THE DATABASES WE ARE USING, THE LABS ARE ALREADY VERY DENSE AND DIFFICULT TO DO TO ON TOP ON THAT THROW US ON THE BLIND\n",
    "## TO WORK WITH A DATABASE WE HAVE NOT A CLUE WHAT IT IS ABOUT. IT TOOK ME LIKE 40 MIN JUST TO UNDERSTAND WHAT THE DATABASE IS ABOUT AND THEN BE ABLE TO DO THE EXERCISES SINCE I NOW UNDERSTAND WHAT\n",
    "## IM BEING ASKED TO DO. AND IT IS NOT OBVIOUS THAT THE DESCRIPTION IS ON THE DOWNLOADED VARIABLE.\n",
    "\n",
    "## NOTICE 2: ALSO THE LAB IS OUTDATED, THE MOMENT I RUN THE FIRST LINE IM GETTING AN ERROR. fetch_mldata IS NOT USED ANYMORE AND MUST BE REPLACED BY ANOTHER PACKAGE. THIS ISSUE IS WELL KNOWN FOR A YEAR\n",
    "## AND I WOULD EXPECT TO NOT ENCOUNTER IT IN A LAB.\n",
    "\n",
    "#Paolo: points taken Victor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def sort_by_target(mnist):\n",
    "    reorder_train = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:, 1]\n",
    "    reorder_test = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:, 1]\n",
    "    mnist.data[:60000] = mnist.data[reorder_train]\n",
    "    mnist.target[:60000] = mnist.target[reorder_train]\n",
    "    mnist.data[60000:] = mnist.data[reorder_test + 60000]\n",
    "    mnist.target[60000:] = mnist.target[reorder_test + 60000]\n",
    "\n",
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "    mnist.target = mnist.target.astype(np.int8)\n",
    "    sort_by_target(mnist)\n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Now take a look at the shapes of the X and y matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  86., 131., 225., 225., 225.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  13.,  73., 197.,\n",
       "       253., 252., 252., 252., 252.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4.,\n",
       "        29.,  29., 154., 187., 252., 252., 253., 252., 252., 233., 145.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  29., 252., 253., 252., 252., 252.,\n",
       "       252., 253., 204., 112.,  37.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       169., 253., 255., 253., 228., 126.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  98., 243., 252., 253., 252., 246.,\n",
       "       130.,  38.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  98.,\n",
       "       240., 252., 252., 253., 252., 252., 252., 221.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 225., 252., 252., 236., 225., 223.,\n",
       "       230., 252., 252.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       146., 252., 157.,  50.,   0.,   0.,  25., 205., 252.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  26., 207., 253.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  29.,  19.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  73., 205., 252.,  79.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 120., 215., 209., 175.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  19., 209., 252., 220.,  79.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 174., 252., 252., 239.,\n",
       "       140.,   0.,   0.,   0.,   0.,   0.,  29., 104., 252., 249., 177.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 174., 252., 252., 223.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 174., 252., 252., 223.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 141., 241., 253.,\n",
       "       146.,   0.,   0.,   0.,   0., 169., 253., 255., 253., 253.,  84.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 178., 252., 154.,  85.,  85., 210., 225.,\n",
       "       243., 252., 215., 121.,  27.,   9.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  66.,\n",
       "       208., 220., 252., 253., 252., 252., 214., 195.,  31.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  19.,  37.,  84., 146., 223.,\n",
       "       114.,  28.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[36000]\n",
    "#Paolo:yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28100410ec8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[36000].reshape(28,28), cmap = plt.cm.binary, interpolation=\"nearest\")\n",
    "#Paolo:yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X_train = X[:60000]\n",
    "X_test = X[-10000:]\n",
    "y_train = y[:60000]\n",
    "y_test = y[-10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_5 = np.where(y != 5, 0, y)\n",
    "y_5 = np.where(y_5 == 5, 1, y_5)\n",
    "\n",
    "y_5_train = y_5[:60000]\n",
    "y_5_test = y_5[-10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9779"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5 = LogisticRegression()\n",
    "# model_5.max_iter = 10000\n",
    "model_5.fit(X_train, y_5_train)\n",
    "\n",
    "y_pred = model_5.predict(X)\n",
    "#Paolo: here you could predict on X_train\n",
    "model_5.score(X_test,y_5_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred    1\n",
       "val     1\n",
       "Name: 36000, dtype: int8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'pred': y_pred, 'val': y_5}).loc[36000]\n",
    "#YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54153, 905, 426, 4516)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_pred, y_5).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63687, 6313, 0, 0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "never_5_clf.fit(X_train, y_5_train)\n",
    "y_predict_dumb = never_5_clf.predict(X)\n",
    "tn, fp, fn, tp = confusion_matrix(y_predict_dumb, y_5).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     64239\n",
      "           1       0.83      0.91      0.87      5761\n",
      "\n",
      "    accuracy                           0.98     70000\n",
      "   macro avg       0.91      0.95      0.93     70000\n",
      "weighted avg       0.98      0.98      0.98     70000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     70000\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91     70000\n",
      "   macro avg       0.50      0.45      0.48     70000\n",
      "weighted avg       1.00      0.91      0.95     70000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_predict_dumb, y_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# From a first glance we see that for value 0 (not a number 5) they both work pretty well, but the first one is slighty better. On the second value (1 for number 5) the first model still has a high\n",
    "# value but slower than for 0, while the second model its completely disastrous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Never5Classifier should be a binary classifer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-2fa0aecde78e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplot_roc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_5_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_roc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnever_5_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_5_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# This gives me an error saying that Never5Classifier is not a binary classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_plot\\roc_curve.py\u001b[0m in \u001b[0;36mplot_roc_curve\u001b[1;34m(estimator, X, y, sample_weight, drop_intermediate, response_method, name, ax, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m         estimator.__class__.__name__))\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     prediction_method = _check_classifer_response_method(estimator,\n",
      "\u001b[1;31mValueError\u001b[0m: Never5Classifier should be a binary classifer"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(model_5, X_test, y_5_test) \n",
    "plot_roc_curve(never_5_clf, X_test, y_5_test) \n",
    "plt.show()\n",
    "# This gives me an error saying that Never5Classifier is not a binary classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_5, y_predict_dumb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9127544190476278"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_5, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# The non dumb model works much better. This metric tells us the area under the curve of our model, which translates to the prediction capacity, the higher the area under the curve, the higher\n",
    "# the probability of predicting 1 as 1 and 0 as 0\n",
    "#paolo: great lab!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
