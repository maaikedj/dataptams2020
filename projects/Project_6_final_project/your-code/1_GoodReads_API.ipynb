{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoodReads API\n",
    "\n",
    "by: Sara Mendoza\n",
    "\n",
    "Data Analytics - Ironhack Amsterdam / cohort Jan - June 2020\n",
    "\n",
    "DATA for Project 6 - June 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "\n",
    "This notebook was used to download data from the GoodReads website.\n",
    "On GoodReads, users can create accounts, by default they all have a \"shelf\" (list) of books called READ.\n",
    "On this shelf all their read books are stored. \n",
    "\n",
    "This notebook loops through many userIDs and creates requests to GoodReads to get the list of books on their read shelf.\n",
    "\n",
    "The GoodReads Api Documentation can be accessed here: https://www.goodreads.com/api/index#shelves.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the needed libraries\n",
    "from goodreads import client\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json \n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GoodReads Api Documentation can be accessed here: https://www.goodreads.com/api/index#shelves.list\n",
    "\n",
    "A developer key is needed, this can be requested here: https://www.goodreads.com/api/keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key and password from GoodReads\n",
    "gc = client.GoodreadsClient('wxwrc6aLfRoMX3Ivr784A','rFT6Ytzh5TRBNcWnAYTdWY1wU5U27fQ6tEegWiSM5M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Getting the UserID's\n",
    "It is not possible to get a list of users from GoodReads, but all users are indexed consecutively from ID 1,\n",
    "for example: https://www.goodreads.com/user/show/1 \n",
    "\n",
    "to ID's with 9 digits, for example:\n",
    "https://www.goodreads.com/user/show/111111111\n",
    "\n",
    "so to access the data I created a function to return random numbers between 1 and 999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return random userid's\n",
    "\n",
    "def createuserIDs(num_users):\n",
    "    i = 0\n",
    "    df = pd.read_csv('../data/goodreads_batch1.csv')\n",
    "    #check to avoid duplicates\n",
    "    batch1 = df['userid'].unique()\n",
    "    mylist = []\n",
    "    while i < num_users:\n",
    "        x = randint(1,99999999)\n",
    "        if x not in mylist and x not in batch1:\n",
    "            mylist.append(x)\n",
    "        i+= 1\n",
    "    return mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially I had also created a function to check if the users were active and public (if inactive or private we will not be able to access their shelf).\n",
    "\n",
    "But GoodReads has a limit of 1 API request per second, and checking over 3,000 users was taking too much time, so I did not use this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing this usercheck, as its only creating more GET requests and slowing down everything\n",
    "# def createuserlist(list_users,userIDs):\n",
    "#     for i in userIDs:\n",
    "#         try:\n",
    "#             user = gc.user(i)\n",
    "#             list_users.append((i,user.name))\n",
    "#             #sleep 1, as they accept max 1 request per second\n",
    "#             sleep(1)\n",
    "#         # adding except: pass, as some users are no longer active\n",
    "#         except:\n",
    "#             pass\n",
    "#     return list_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Creating the GET request\n",
    "This function takes a userID and through the API access their read shelf.\n",
    "Unfortunately there is no specific method to download only the book titles + rating, so I had to donwload all the information on their page, parse it and select what I needed.\n",
    "\n",
    "Also, as the function to check if userIDs are active and public was removed, we will also be looping through inactive or private users, which will return 3 empty lists. The empty lists will be removed later, and this way was faster than  creating 2x GET requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createshelve_read(user):\n",
    "    userID = []\n",
    "    books = []\n",
    "    ratings = []\n",
    "    try:\n",
    "        url = 'https://www.goodreads.com/review/list/' + str(user) +'.xml?key=wxwrc6aLfRoMX3Ivr784A&v=2&per_page=200&shelf=read'\n",
    "        html = requests.get(url).content\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        for element in soup.find_all('title_without_series'):\n",
    "            books.append(element.text)\n",
    "        for element in soup.find_all('rating'):\n",
    "            ratings.append(element.text)\n",
    "        #sleep 1, as they accept max 1 request per second\n",
    "        sleep(1)\n",
    "        for i in range(len(books)):\n",
    "            userID.append(user)\n",
    "    # adding except: pass, as some users are private and you cannot download their info\n",
    "    except:\n",
    "        pass\n",
    "    return userID, books, ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Getting the Data\n",
    "\n",
    "Since we are not checking if users are active or public, I wanted to download at least info for 3,000 users. Thinking that worst case scenario 1/3 will be inactive or private and 1/3 will be active but have little to no info on their account. This would leave us with a total of 1,000 users info.\n",
    "\n",
    "The function for the GET request has a 1 second sleep, since GoodReads limits 1 API request per second, and blocks users who dont comply. Thats 3000 seconds for 3000 users or 50 min. In reality it took close to 2 hours to run the entire file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some random userIDs\n",
    "userIDs = createuserIDs(3000)\n",
    "\n",
    "#adding myself :-) in batch1\n",
    "#userIDs.append(42889636)\n",
    "\n",
    "#adding other friends for batch2\n",
    "# Zuzanna: 29153227\n",
    "# Mom: 45188186\n",
    "# Melissa: 48794835\n",
    "# Paolo: 6940448\n",
    "\n",
    "# more_users = [29153227,45188186,48794835,6940448]\n",
    "# for i in more_users:\n",
    "#     userIDs.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Running in Batches\n",
    "Because the file kept freezing or not running to completion, I decided to split the userIDs into different batches of 500 and saving the info in each run and then merging at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list where all the info will be stored\n",
    "alldata = []\n",
    "\n",
    "# RUN 1\n",
    "\n",
    "# selecting only 500 users at the time\n",
    "for i in userIDs[:500]:\n",
    "    result = createshelve_read(i)\n",
    "    alldata.append(result)\n",
    "\n",
    "# printing to make sure we are actually saving data in each round (learned from past experiences of letting it run for 2 hours and having no data...)\n",
    "print(len(alldata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN 2\n",
    "\n",
    "for i in userIDs[500:1000]:\n",
    "    result = createshelve_read(i)\n",
    "    alldata.append(result)\n",
    "len(alldata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN 3\n",
    "\n",
    "for i in userIDs[1000:1500]:\n",
    "    result = createshelve_read(i)\n",
    "    alldata.append(result)    \n",
    "len(alldata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN 4\n",
    "\n",
    "for i in userIDs[1500:2000]:\n",
    "    result = createshelve_read(i)\n",
    "    alldata.append(result)\n",
    "len(alldata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN 5\n",
    "\n",
    "for i in userIDs[2000:2500]:\n",
    "    result = createshelve_read(i)\n",
    "    alldata.append(result)\n",
    "len(alldata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN 6\n",
    "\n",
    "for i in userIDs[2500:]:\n",
    "    result = createshelve_read(i)\n",
    "    alldata.append(result)\n",
    "len(alldata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting it all in one data frame\n",
    "\n",
    "userID = [i[0] for i in alldata]\n",
    "books = [i[1] for i in alldata]\n",
    "ratings = [i[2] for i in alldata]\n",
    "\n",
    "flat_userID = [item for sublist in userID for item in sublist]\n",
    "flat_books = [item for sublist in books for item in sublist]\n",
    "flat_ratings = [item for sublist in ratings for item in sublist]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'userid' : flat_userID,\n",
    "    'book' : flat_books,\n",
    "    'rating' : flat_ratings,\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the data in a CSV\n",
    "\n",
    "# first batch downloaded on 23/06\n",
    "# df.to_csv('../data/goodreads_batch1.csv',index=False)\n",
    "\n",
    "# second batch downloaded on 25/06\n",
    "# df.to_csv('../data/goodreads_batch2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
