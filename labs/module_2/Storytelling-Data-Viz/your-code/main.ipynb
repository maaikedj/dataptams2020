{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Storytelling Data Visualization Lab\n",
    "\n",
    "In this lab you'll use a dataset called `housing_prices.csv` which contains the sales data of houses. The dataset and descriptions of the columns are available from [Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data). For your convenience, you can review the descriptions of the data columns from [here](https://drive.google.com/file/d/1-iXooLjNuEXU41dqz8ORQ5JEZPHd9x0X/view?usp=sharing).\n",
    "\n",
    "Pretend you are a data analyst at an investment company where the board decided to make investments in real estates. Your boss asked you to analyze this housing sales dataset and present to the investment managers on **what features of houses are strong indicators of the final sale price**. You need to present your findings in intuitive ways so that the investment managers understand where your conclusions come from.\n",
    "\n",
    "#### You will use the appropriate data visualization graphs to tell your stories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Challenge 1 - Understanding the Dataset\n",
    "\n",
    "After receiving the data and clarifying your objectives with your boss, you will first try to understand the dataset. This allows you to decide how you will start your research in the next step.\n",
    "\n",
    "The dataset is [here](https://drive.google.com/file/d/1MRhRtdX8QuPPEhelBIS_FEl5vJjRLSeE/view?usp=sharing). Please download it and place it in the data folder.<br>\n",
    "First, import the basic libraries and the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('../data/housing_prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### As a routine before analyzing a dataset, print the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "You find the dataset has 81 columns which are a lot. \n",
    "\n",
    "#### Since the column `Id` is meaningless in our data visualization work, let's drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "df.drop('Id',1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "You care about missing values. If a column has too many missing values, it is not reliable to use it to predict sales price.\n",
    "\n",
    "#### In the cell below, calculate the percentage of missing values for each column. \n",
    "\n",
    "Make a table containing the column name and the percentage of missing values. Print the columns where more than 20% of values are missing. An example of what your output  should look like is [here](https://drive.google.com/file/d/1cuq6qhFZC5wavm-_STcxktBKdAc4xvH8/view?usp=sharing)\n",
    "\n",
    "[This reference](https://stackoverflow.com/questions/51070985/find-out-the-percentage-of-missing-values-in-each-column-in-the-given-dataset) can help you make the missing values table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,'percent_missing': percent_missing})\n",
    "#missing_value_df.sort_values(by =['percent_missing']> 20, inplace=True)\n",
    "#error \">\" not supported between instances of 'list' and 'int'\n",
    "missing_value_df.sort_values(by =['percent_missing'], inplace=True)\n",
    "missing_value_df=missing_value_df[missing_value_df['percent_missing']>20]\n",
    "missing_value_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Drop the columns you find that have more than 20% missing values.\n",
    "\n",
    "After dropping, check the shape of your dataframes. You should have 75 columns now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "for column in missing_value_df['column_name'][missing_value_df.percent_missing > 20]:  \n",
    "    df.drop(column,1,inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Since you're asked to analyze sale prices, first let's see if the sale prices (column `SalePrice`) has a normal distribution. This is important because normally distributed data can be better represented with mathematical models.\n",
    "\n",
    "#### In the cell below, use the propriate graph to visualize the shape of distribution of the sale prices. Then explain what you find from the graph about data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "sns.distplot(df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# your comment here\n",
    "#The data is not normally distributed - strongly skewed to the left, with the right tail being significantly longer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Bonus Challenge 1 - Adjust Data Distribution\n",
    "\n",
    "If you used the correct method in the previous step, you should have found the data distribution is skewed to the left. In order to improve your data visualization in the next steps, you can opt to adjust the `SalePrice` column by applying a mathematical function to the values. The goal is to produce a bell-shape normal distribution after applying the mathematical function to the sale price.\n",
    "\n",
    "*This technique is optional in data visualization but you'll find it useful in your future machine learning analysis.*\n",
    "\n",
    "#### In the cell below, adjust the `SalePrice` column so that the data are normally distributed.\n",
    "\n",
    "Try applying various mathematical functions such as square root, power, and log to the `SalePrice` column. Visualize the distribution of the adjusted data until you find a function that makes the data normally distributed. **Create a new column called `SalePriceAdjusted` to store the adjusted sale price.**\n",
    "\n",
    "[This reference](https://trainingdatascience.com/workshops/histograms-and-skewed-data/) shows you examples on how to adjust skewed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Challenge 2 - Exploring Data with Common Sense\n",
    "\n",
    "Now that we have a general understanding of the dataset, we start exploring the data with common sense by means of data visualization. Yes, in data analysis and even machine learning you are often required to use common sense. You use your common sense to make a scientific guess (i.e. hypothesis) then use data analytics methods to test your hypothesis.\n",
    "\n",
    "This dataset is about housing sales. According to common sense, housing prices depend on the following factors:\n",
    "\n",
    "* **Size of the house** (`GrLivArea`, `LotArea`, and `GarageArea`).\n",
    "\n",
    "* **Number of rooms** (`BedroomAbvGr`, `KitchenAbvGr`, `FullBath`, `HalfBath`, `BsmtFullBath`, `BsmtHalfBath`).\n",
    "\n",
    "* **How long the house has been built or remodeled** (`YearBuilt` and `YearRemodAdd`).\n",
    "\n",
    "* **Neighborhood of the house** (`Neighborhood`).\n",
    "\n",
    "#### In this challenge, use the appropriate graph type to visualize the relationships between `SalePrice` (or `SalePriceAdjusted`) and the fields above. \n",
    "\n",
    "Note that:\n",
    "\n",
    "* Transform certain columns in order to visualize the data properly based on common sense. For example:\n",
    "    * Visualizing how the number of half bathrooms affected the sale price probably does not make sense. You can create a new column to calculate the total number of bathrooms/rooms then visualize with the calculated number.\n",
    "    * `YearBuilt` and `YearRemodAdd` are year numbers not the age of the house. You can create two new columns for how long the house has been built or remodeled then visualize with the calculated columns.\n",
    "* Make comments to explain your thinking process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# add cells as needed\n",
    "df['House Size']=df['GrLivArea']+df['LotArea']+ df['GarageArea']\n",
    "df['Bathrooms'] = df['FullBath'] + df['HalfBath'] + df['BsmtFullBath'] + df['BsmtHalfBath']\n",
    "df['Rooms Number']=df['BedroomAbvGr'] + df['KitchenAbvGr'] + df['Bathrooms']\n",
    "df['Years Built']=2020 - df['YearBuilt']\n",
    "df['Years Remodeled']=2020 - df['YearRemodAdd']\n",
    "df['Years Built and Remodeled']=  df['Years Built'] + df['Years Remodeled']\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_area= df[['GrLivArea','LotArea', 'GarageArea']]\n",
    "total_area['Total Area']=total_area['GrLivArea']+total_area['LotArea']+ total_area['GarageArea']\n",
    "total_area.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization: Size of the house vs SalePrice\n",
    "#plt.bar(df['House Size'], df['SalePrice'])\n",
    "#plt.xlabel('House Size')\n",
    "#plt.ylabel('Price')\n",
    "#plt.title('House Size vs Sale price')\n",
    "#plt.show()\n",
    "#doesn't look great; values too low \n",
    "sns.jointplot(x=\"House Size\", y=\"SalePrice\", data = df, kind=\"hex\", color=\"k\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"House Size\", y=\"SalePrice\", data=df, kind=\"kde\")\n",
    "#i'd like to zoom it in here, but I'm not sure how to  - maybe by plot division?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization Number of rooms vs SalePrice\n",
    "plt.bar(df['Rooms Number'], df['SalePrice'])\n",
    "\n",
    "plt.xlabel('Rooms Number')\n",
    "plt.ylabel('Price')\n",
    "plt.title(' Rooms Number vs Sale price')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vizualization How long the house has been built or remodeled vs SalePrice\n",
    "\n",
    "plt.bar(df['Years Built and Remodeled'], df['SalePrice'])\n",
    "\n",
    "plt.xlabel('Years Built and Remodeled')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Years Built and Remodeled vs Sale price')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vizualization Neighborhood of the house (Neighborhood) vs SalePrice  \n",
    "#ax = sns.violinplot(x=\"Neighborhood\", y=\"SalePrice\", hue=\"Neighborhood\",\n",
    "                    #data=df, palette=\"muted\")\n",
    "    #doesn't look Clean; flip and increse size for more visibility \n",
    "sns.violinplot(y=\"Neighborhood\", x=\"SalePrice\",\n",
    "                    data=df, palette=\"muted\", figsize=(250,100))   \n",
    "#not sure how to make it more readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Bonus Challenge 2 - Exploring Data with Correlation Heatmap\n",
    "\n",
    "Now you have explored data visualizations with certain fields based on common sense. In the dataset there are many other fields that you are not sure whether they are important factors for the sale price. What is the best way to explore those fields without investigating them individually?\n",
    "\n",
    "Making scatter matrix is not an option here because there are too many fields which makes it extremely time consuming to create scatter matrix. One option you have is to create a heatmap. Heatmaps are much less expensive to create than scatter matrixes. You can use heatmaps to visualize the pairwise correlations between each two variables.\n",
    "\n",
    "Here is a [reference](https://seaborn.pydata.org/examples/many_pairwise_correlations.html) you can use to learn how to creat the pairwise correlation heatmap. Your heatmap should look like this [example](https://drive.google.com/file/d/1JhdNvbAnnWDFXEtDoBtx3B2KKIkqsnSH/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Generate a large random dataset\n",
    "rs = np.random.RandomState(33)\n",
    "d = pd.DataFrame(data=df, columns=df.columns)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = d.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "In your heatmap, you can easily identify the highly correlated (either positively or negatively) variables by looking for the grids with darker colors. \n",
    "\n",
    "#### In the cell below, summarize what variables are highly correlated to the sale price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# your comment here \n",
    "#Negatively correlated: lot area; Year Built; Year Removed; FullBath; Garage (cluster: GarageYrBlt; GarageCars; GarageArea); Sale Price; Bathrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Challenge 3 - Present Your Stories\n",
    "\n",
    "Now based on your findings from the explorations, summarize and present your stories.\n",
    "\n",
    "#### Present the top 5 factors that affect the sale price.\n",
    "\n",
    "Use the following format to present each factor:\n",
    "\n",
    "1. A title line about the factor.\n",
    "\n",
    "1. No more than 3 sentences to describe the relationship between the factor and the sale price.\n",
    "\n",
    "1. Support your point with the appropriate graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# your responses here\n",
    "# add cells as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor 1: Rooms Number "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rooms number seems most normally distributed in terms of correlation. It is not fully normally distributed; with right skewness - reaching the peak at 10 rooms; but dropping at 12 and 14 rooms; and showing a higher proce for 6-room than 8-room apartments. \n",
    "Reference graph: Challenge 2; Bar plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor 2: House Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "House size is positively correlated with prce, almost in purely linear fashion. This can be intuitivelty expected, but was illustrated with data vizualization in Challenge 2; Hexbin and Kernel density plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor 3 & 4: Year built; Year Remodelled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price decreases along with the time built/remodelled, except for peaks at about 50 and 160 years. \n",
    "This may be due to specific construction properties or architectural preference of those periods; versus otherwise preferred new-builds. Graph reference: Bar graph, Challenge 2; Heat Map, Bonus Challenge 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor 5: Neighbourhood "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sale price seems to be influenced by neighbourhood placement; both in terms of minimum & maximum values range; and distribution. \n",
    "The highest-price-ranking neighbourhoods are: \"NoRidge\"; \"NridgHt\"; \"StoneBr\"\n",
    "The lowest-price-ranking neighbourhoods are: \"NPkVill\"; \"BrDale\"; \"Meadow\"\n",
    "Graph reference: Violin graph; Challenge 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
