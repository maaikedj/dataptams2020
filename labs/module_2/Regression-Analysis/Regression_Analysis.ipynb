{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0KNazO8T9BaV"
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5QjejZ1d9RvH"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "We have already learned about how two variables can be related through correlation (two variables move together: both increase and decrease together, or one increases while the other decreases). \n",
    "\n",
    "**In regression analysis, we will learn about how groups of variables can be correlated to a single target, or outcome, variable, and how these relationships can be used *to predict the future values of that outcome*.** We call the variables that are correlated with the outcome independent, or X variables, and the outcome variable the dependent, or Y variable. \n",
    "\n",
    "Regression analysis is one of the most common techniques used to make predictions. Depending on the question we would like to answer, and the format of the outcome variable, regression analysis can be used to both make **value predictions (what will my income be next year?)** and **classifications (based on the qualities of a song, will I like it or not?)**. The relationship between the X variables and the Y variables can also take different formats. The case that an increase or decrease in an X variable always produces the same, fixed increase or decrease in the Y variable is called **linear regression.** When this relationship is not always the same we classify it as **non-linear regression.**\n",
    "\n",
    "In some cases, there is only one predictor variable, which makes the relation a simple **(univariate) linear regression.** In other cases, there are more than one predictor variables which is called **multiple (multivariate) linear regression.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G4VHnFgq9TcJ"
   },
   "source": [
    "\n",
    "\n",
    "*   Linear Regression:\n",
    "\n",
    "\n",
    "*   Non-linear Regression: \n",
    "\n",
    "![alt text](https://sixsigmastudyguide.com/wp-content/uploads/2019/11/non0.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MnQfwfL-oo8"
   },
   "source": [
    "## Simple Linear Regression (Univariate)\n",
    "\n",
    "Univariate analysis, or simple linear regression, is when only one X (independent) variable is used to predict the outcome variable. In the case of linear univariate analysis, we can model this relationship using a straight line. The mathetical formula is:\n",
    "\n",
    "$$Y = \\beta_{0} + \\beta_{1} X,$$\n",
    "\n",
    "where:\n",
    "\n",
    "\n",
    "*   X - Independent variable;\n",
    "*   Y - Dependent variable;\n",
    "*   $\\beta_{1}$ - the quantity of change (positive or negative) that one can expect from a one unit increase in X. If we increase X by one unit, Y will increase by $\\beta_{1}$ units. This is also sometimes referred to as ‘slope’; \n",
    "*   $\\beta_{0}$ - intercept (or constant). This is the value at which the regression line crosses the y axis. \n",
    "\n",
    "![alt text](http://www.sthda.com/english/sthda-upload/images/machine-learning-essentials/linear-regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oPNuVrSR-xPr"
   },
   "source": [
    "### Example 1: Python Implementation of Univariate Linear Regression\n",
    "\n",
    "In this exercise, we will use data from a Fitbit, a personal health monitor. This dataset includes information on an individual’s activity levels (steps, calories, heart rate), exercise, sleep, as well as assorted community and personal profile information added by the user. Here we will use the Fitbit2.csv file and look at two specific columns related to sleep quality, ‘MinutesOfBeingAwake’ and ‘NumberOfAwakings’. Below, we use python code to build a scatter plot of the two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9Ui8Zl68-DP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1587056001141,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "SePQ06hY_zJw",
    "outputId": "f243d42e-6f68-4080-89ab-07dd631d8dcf"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/loukjsmalbil/datasets_ws/master/Fitbit2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 761,
     "status": "ok",
     "timestamp": 1587056004658,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "O8fOzuzMM8qe",
    "outputId": "371b7968-c0db-4a03-ce53-114a039a822b"
   },
   "outputs": [],
   "source": [
    "data[[\"NumberOfAwakings\", \"MinutesOfBeingAwake\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1565,
     "status": "ok",
     "timestamp": 1587056021460,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "nV47JAGEAAMa",
    "outputId": "4bd3bb75-3901-44f2-93bd-5c81259e6981"
   },
   "outputs": [],
   "source": [
    "sns.regplot(x=\"NumberOfAwakings\", y=\"MinutesOfBeingAwake\", data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BelgTkxYAL1r"
   },
   "source": [
    "Here, we can see that as the number of awakenings increases, so does the number of minutes of being awake. This makes sense, given that if you wake up more times in the night, you will also likely be awake for more time (even if you wake up for a short time).\n",
    "\n",
    "But what on average, how many more minutes are you awake if you wake up one more time during the night? In other words, we want to know what is the slope of this line. We can answer this question if we establish a linear mathematical equation/relation between the two variables:\n",
    "\n",
    "$$[MinutesOfBeingAwake] = b0 + b1*[NumberOfAwakings]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nm7JEwhdAOWs"
   },
   "source": [
    "Here, the slope, or $\\beta_{1}$, will tell us the average increase in awake time if we wake up one more time during the night. \n",
    "\n",
    "We can also see on the graph that the fitted line does not start at the origin (where the X and Y axes meet at 0,0). This means that the intercept, or where this line crosses the Y axis ($\\beta_{0}$) will not be equal to zero, but to the value at which the line crosses the axis. \n",
    "\n",
    "The following Python code example shows you how to calculate the intercept and slope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJVHS5vtARfy"
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "de8P678BAUqy"
   },
   "outputs": [],
   "source": [
    "X = data['NumberOfAwakings']\n",
    "Y = data['MinutesOfBeingAwake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qfk9Y6FoAYZO"
   },
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1587056295993,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "0ohtWh-zAhf2",
    "outputId": "55cc80bf-ac2d-45ec-ed1f-f0320166423d"
   },
   "outputs": [],
   "source": [
    "print ('The slope is, b1: ' + str(slope))\n",
    "print ('The intercept is, b0: ' + str(intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_KHH3aUBEOz"
   },
   "source": [
    "We now know all the terms in our forumla. However, when working with large quantities of data, it is often easier to build a regression model. Let's have a look at how we would do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBmy7qTBAkOZ"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uTV_FsO9oIqm"
   },
   "source": [
    "Before we move on, let us have a look at a visualisation of the method we will use to fit our data: https://seeing-theory.brown.edu/regression-analysis/index.html#section1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gknZWL49BS4i"
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(Y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sowd17qzBWVJ"
   },
   "outputs": [],
   "source": [
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "icvWylOoBXwr"
   },
   "outputs": [],
   "source": [
    "predictions = results.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1587056753991,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "T8LsdVcABh3a",
    "outputId": "d080b64c-f9b4-445d-aaf8-6d8e82e8a6da"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'observed':Y, 'predicted':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1587056836426,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "rYTAyFzJB2lb",
    "outputId": "246cc86f-414a-4540-eb1e-b7dbec34a94d"
   },
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8q9EcnSzCEji"
   },
   "source": [
    "## Non-Linear Regression\n",
    "\n",
    "It is possible that the relationship between an X variable and the Y variable is not linear. In this case, we have to add non-linearities to the mathematical model that we use. For example, if the non-linear relationship was quadratic, the univariate non-linear model could be written as below:\n",
    "\n",
    "$$Y = \\beta_{0} + \\beta_{1} X^{2}$$\n",
    "\n",
    "We will explore more complex non-linear models later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VRBUurmRA8il"
   },
   "source": [
    "where $Y$ is still the same, but we have added additional $X$’s to our equation. **We will use additional columns from the dataset to include as the predictor variables (hence multiple linear regression).** Please note that for now we are only using the columns that have numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZutWOhzpAt7H"
   },
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "We just explored how to predict an outcome using just one X variable. Now, let’s consider the case that we have multiple variables that all work together to explain the outcome variable. For instance, using the data above, let’s say we still want to predict the number of minutes a person is awake during the night. We think that this outcome could be determined by multiple factors in addition to the number of times a person wakes up during the night: the minutes of sleep they get overall, and their daytime activity level (maybe people who are more active are likely to sleep more).\n",
    "\n",
    "We could add these variables to the same model we used before by finding the betas for each of these variables, and adding them to our equation:\n",
    "\n",
    "$$Y = \\beta_{0} + \\beta_{1} X_{1} + ... + \\beta_{n} X_{n}.$$\n",
    "\n",
    "An example of this for 2 independent variables:\n",
    "\n",
    "![alt text](https://miro.medium.com/max/1120/0*AqzOn7p--nveVULA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "41pC3yV-CYvq"
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "**Now, let’s imagine that the outcome we are interested in can only be one of two options. These problems are also known as classification/segmentation problem.** For example, consider the example of churn  for credit card companies. Churn is when a customer stops using a service in a certain period of time. Credit card companies want to retain as many customers as possible, so they are interested in predicting if a consumer will leave (churn) or not. Based on the historical data, they want to find out if the customer will continue using the card after a year or not. \n",
    "\n",
    "This problem can be answered by labeling the customers as *Yes (will churn)* or a *No (will not churn)*. This is a classic binary classification problem: there are two output choices. Similarly, when there are more than two output choices, it is called multi-class classification. We will talk about multi-class classification in later lectures.\n",
    "\n",
    "Logistic Regression is a type of regression that allows for the outcome variable to be binary. Below, we can see that the shape of the logistic line allows for our outcome to be 0 or 1 (or some probability in between that we can round to 0 or 1). \n",
    "\n",
    "The mathematical way of writing this is as follows:\n",
    "\n",
    "$$p(y) = \\frac{1}{1 + e^{\\beta_{0} + \\beta_{1}X_{1} + ... \\beta_{n}X_{n}}}.$$\n",
    "\n",
    "\n",
    "This is also called a Sigmoid and it is displayed below:\n",
    "\n",
    "![alt text](https://static.javatpoint.com/tutorial/machine-learning/images/logistic-regression-in-machine-learning.png)\n",
    "\n",
    "The idea here is that we assign some probability-value to a costumer. This probability indicates whether he or she will Churn (*Yes* or *No*). Usually, if p > 0.5, we will assign a 1 and a 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jer02fe1Cp8K"
   },
   "source": [
    "### Example: Python Implementation of a Logistic Regression\n",
    "\n",
    "Using Python to make Logistic Regression Model\n",
    "\n",
    "We will use churn data for this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pMt4CBlUC4Qv"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 748,
     "status": "ok",
     "timestamp": 1587057468416,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "1GEC7t5aB5tH",
    "outputId": "0658f3b4-d956-43a6-be29-8b4e14a53a26"
   },
   "outputs": [],
   "source": [
    "churnData = pd.read_csv('https://raw.githubusercontent.com/haggarw3/Datasets/master/Customer-Churn.csv')\n",
    "churnData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQvlPfD7C9WB"
   },
   "outputs": [],
   "source": [
    "numericData = churnData[['tenure','SeniorCitizen','MonthlyCharges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 519,
     "status": "ok",
     "timestamp": 1587057522729,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "QighV-SHC_yy",
    "outputId": "a9206f3a-9de8-4a4c-9bda-47639f55ae7b"
   },
   "outputs": [],
   "source": [
    "numericData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bcan7U5DDBFN"
   },
   "outputs": [],
   "source": [
    "Y = pd.DataFrame(data=churnData, columns=['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aXdYgxlAIt2"
   },
   "outputs": [],
   "source": [
    "#Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9-kmFyzCDEpb"
   },
   "outputs": [],
   "source": [
    "transformer = StandardScaler().fit(churnData[['tenure','SeniorCitizen','MonthlyCharges']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U-jPjXKMQh37"
   },
   "source": [
    "We will use a StandardScaler to transform and scale our data such that its distribution will have a mean value 0 and standard deviation of 1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1587057640550,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "JTPe_GVbDS8t",
    "outputId": "1cd1e492-4945-41ee-f03f-5bd450ba9a7f"
   },
   "outputs": [],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HntLpJHDI2S"
   },
   "outputs": [],
   "source": [
    "scaled_x = transformer.transform(churnData[['tenure','SeniorCitizen','MonthlyCharges']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 526,
     "status": "ok",
     "timestamp": 1587057655825,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "WnDK60oRDYJy",
    "outputId": "5137ec86-9cca-4610-cae6-4f027277bd06"
   },
   "outputs": [],
   "source": [
    "scaled_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Hyzmagtw1K1"
   },
   "source": [
    "Then we feed this scaled data to our logistic regression algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZHfD2AW_DYZ6"
   },
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_results = lr_model.fit(scaled_x, churnData['Churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1181,
     "status": "ok",
     "timestamp": 1587058057689,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "YWiyrpwVDwWa",
    "outputId": "3eab30b9-2304-4bdf-8799-799f7a1858d4"
   },
   "outputs": [],
   "source": [
    "lr_predicted = lr_results.predict(scaled_x)\n",
    "lr_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDK3VHrusk9Y"
   },
   "outputs": [],
   "source": [
    "#predicted_logis = classification.predict(scaled_x)\n",
    "lr_predicted_df = pd.DataFrame(lr_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 495,
     "status": "ok",
     "timestamp": 1587058063012,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "1rt7RCAbsH0K",
    "outputId": "3edaeff5-f999-4420-8e41-35925223614c"
   },
   "outputs": [],
   "source": [
    "pred_true = pd.concat((lr_predicted_df, Y), axis = 1)\n",
    "pred_true = pred_true.rename(columns= {0:\"Predicted\", \"Churn\": \"True\"})\n",
    "pred_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ALPHyE_aEEx4"
   },
   "source": [
    "Now, for a particular combination of values for the X variables, we can make a prediction of the probability of the consumer churning. When we subject these predictions to a cutoff (ex: all probabilities above .5 are rounded to 1) we can predict if a consumer will churn or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gr8UUTL6rq99"
   },
   "source": [
    "Let us have a look at us have a look at a prediction the model makes for a new customer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btC6bnuJWMfh"
   },
   "outputs": [],
   "source": [
    "#churnData[['tenure','SeniorCitizen','MonthlyCharges']]\n",
    "john = np.array([34, 1, 123.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1587058159071,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "DUuVb_aRWjqR",
    "outputId": "6470c229-cb67-4821-944c-e84f1605d4e9"
   },
   "outputs": [],
   "source": [
    "john.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "82Y653gOWnC5"
   },
   "outputs": [],
   "source": [
    "john = john.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJfH_9CNWMie"
   },
   "outputs": [],
   "source": [
    "transformer_new_cust = StandardScaler().fit(john)\n",
    "john = transformer_new_cust.transform(john)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 580,
     "status": "ok",
     "timestamp": 1587058389155,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "SiNptha2WMl6",
    "outputId": "5c188ce3-8afb-4a56-9c7b-95094deba9b3"
   },
   "outputs": [],
   "source": [
    "lr_results.predict(john.reshape(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r01znNyjEJ21"
   },
   "source": [
    "## Evaluation (Linear) Regressions\n",
    "\n",
    "Now we know how to predict a value for the outcome variable based on some data about the X variables. But how do we know that the line we have fitted to, or chosen to represent, our data is an accurate or inaccurate representation of the true relationship between the variables? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_al0_ljEOOY"
   },
   "source": [
    "### Fitted Values and Residuals\n",
    "An important concept for understanding how well a line ‘fits’ is call the residuals.\n",
    "\n",
    "First, **we know that our model has made some predictions for the value of Y. These are ‘fitted values’ and are denoted by y-hat.** These values lie on the line that we have drawn through our data. We can calculate these values like this:\n",
    "\n",
    "$$predictions = [intercept + slope*x \\text{for} x in X],$$\n",
    "\n",
    "where $y$ denotes the true value and $\\hat{y}$ the predicted value.\n",
    "\n",
    "Let’s imagine that we save some of our Y values to compare to those Y values that our model predicts. The residual is the difference between the original value and the predicted value (error of the prediction, denoted by e-hat): \n",
    "\n",
    "$$e_{i} = y_{i} - \\hat{y}_{i}.$$\n",
    "\n",
    "In Python, we can calculate the residuals like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ae_gAOKunTZF"
   },
   "outputs": [],
   "source": [
    "# Fit the model again\n",
    "X = data['NumberOfAwakings']\n",
    "Y = data['MinutesOfBeingAwake']\n",
    "\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "predictions = results.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kuFtaYvenLoH"
   },
   "outputs": [],
   "source": [
    "# Compute the resisudals\n",
    "residuals = [Y[i] - predictions[i] for i in range(len(Y))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 676,
     "status": "ok",
     "timestamp": 1587058698182,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "wCnnNZb5nlga",
    "outputId": "f469a4a7-862c-4b57-8350-a939154f9c00"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'observed':Y, 'predicted':predictions, 'Difference (Residual)': residuals})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0H9nofDEZLZ"
   },
   "source": [
    "###How to find the best fitting model?\n",
    "\n",
    "The way we draw the line in our data is the principal way in which we ensure that our line is a good ‘fit’. So how do we draw this line most accurately?\n",
    "\n",
    "This is where the concept of residuals comes in. Least Squares Estimation or commonly known as OLS (ordinary least squares) finds the best line that fits the data such that the sum of the squared errors/residuals is minimized. The theory is the ideal straight line we draw should have the minimal total distances (errors) from all the data points. But because the residual values can be negative, we use the squared errors (squaring ensures that all the resulting values are positive). It is helpful to imagine this method as drawing a line that seems like it fits the data well, comparing the original value and the predicted value to obtain the residual, and then repeatedly re-drawing and adjusting the line so the total of all the residuals for all of the points is as small as possible.  It is important to note that this method is computationally inexpensive, but sensitive to outliers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4CQBXmvEdyu"
   },
   "source": [
    "### Model Accuracy \n",
    "**RMSE** (Root Mean Squared Error) is a measure of the overall accuracy of the model. It is the square root of the average squared error (or residual). Mathematically this is calculated as: \n",
    "\n",
    "$$\\text{RMSE} = \\sqrt{     \\frac{\\sum_{i=1}^{N}  (\\hat{y}_{i} - y_{i})^{2}     }{N}  }.$$\n",
    "\n",
    "To calculate RMSE in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZ_kA6rLzqs9"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqcORtkzDx7z"
   },
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(np.mean([residual**2 for residual in residuals]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 686,
     "status": "ok",
     "timestamp": 1587059004074,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "ydQ9_-rmzhlO",
    "outputId": "f5c49646-2943-4f8c-ad21-111e66133404"
   },
   "outputs": [],
   "source": [
    "print('The mean squared error of our model is:', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j2zupzYlEoOI"
   },
   "source": [
    "**Given it is based off the errors in the Y variable, the RMSE has the same units as the outcome variable.** Lower values mean that variation in the data that the model does not explain is low, indicating a better fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ue2rDXx9Ep95"
   },
   "source": [
    "**R squared:** This is another important statistic used to measure the accuracy of the model. It ranges from 0 to 1 and it measures the proportion of variation in the data that the model is able to capture. Usually the larger the value of R square, better is the model.  But this is not always true. We will talk about this in more detail later in this lesson. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_4r8IsPjEuvu"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1587059594727,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "dQGsebry0BIp",
    "outputId": "4499e210-7222-433b-8dc9-d6304e665a96"
   },
   "outputs": [],
   "source": [
    "print('The r-squared score of our model is:', r2_score(Y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1587059608071,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "KyiEL28v0XZf",
    "outputId": "35bfe55b-a088-4fb3-882a-27caab93f8aa"
   },
   "outputs": [],
   "source": [
    "print('The root mean squared error of our model is:', np.sqrt(mean_squared_error(predictions, Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BVHV2Rc0iCS"
   },
   "source": [
    "## Evaluation (Logistic) Regressions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E6G1xrTsEsm2"
   },
   "source": [
    "Using the multivariable model we built with our Fitbit data, we can investigate some of these evaluation metrics using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0thwEXDMd7Wf"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1587059669692,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "iIYesjEVILP6",
    "outputId": "2a93c952-f382-4b02-e6ae-a0b867d43777"
   },
   "outputs": [],
   "source": [
    "churnData['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKmnVp2X11uV"
   },
   "outputs": [],
   "source": [
    "# Convert yes and no to binary ints\n",
    "churnData['Churn'] = churnData['Churn'].replace('Yes', 1)\n",
    "churnData['Churn'] = churnData['Churn'].replace('No', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YtcwOpxi11xh"
   },
   "outputs": [],
   "source": [
    "# Y\n",
    "Y = churnData['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1587059688111,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "3eTEXzHe0w-V",
    "outputId": "fc244fd1-d9ba-4e2f-d1ff-b3554e63556a"
   },
   "outputs": [],
   "source": [
    "# Train the model once again\n",
    "lr_model =  LogisticRegression()\n",
    "lr_results = lr_model.fit(scaled_x, Y)\n",
    "lr_predicted = lr_results.predict(scaled_x)\n",
    "lr_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCjzGAnVaiN3"
   },
   "source": [
    "We will now evaluate the model using the accuracy metric. This metric simply measures how many predictings were correct divided by the total number of predictions. More information can be found [here](https://developers.google.com/machine-learning/crash-course/classification/accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1587059715173,
     "user": {
      "displayName": "Louk Smalbil",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiByqcfGW98Bn42uapsD4oj4auyrLV9xURPKHUj=s64",
      "userId": "10422991521784029462"
     },
     "user_tz": -120
    },
    "id": "ogjgEWY3EzL1",
    "outputId": "f188f342-18eb-430b-e673-c18ccf7d8b52"
   },
   "outputs": [],
   "source": [
    "# Compute the accoracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(lr_predicted, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n0aEDjH5EyMU"
   },
   "source": [
    "As we have seen, Linear Regression is a very useful model. However, it has some limitations, and therefore is best used in specific situations. These limitations come from the assumptions that the model makes about the relationships between variables in the data.\n",
    "\n",
    "\n",
    "\n",
    "* Relationship between the outcomes and the predictors is linear.\n",
    "* Errors are uncorrelated\n",
    "* Errors are normally distributed with mean 0 and constant variance.\n",
    "\n",
    "To check these assumptions we use residual analysis plots such as QQ plot / Quantile Plots, normal probability plots of the residuals, plots of the residuals vs fitted values. We will not go over these methods in this class but it is worth mentioning. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1OmcAr6iE8aD"
   },
   "source": [
    "## Summary \n",
    "\n",
    "In this lesson we learned about univariate and multivariable linear regression and logistic regression techniques. We also explored some applications of regression analysis to solve problems of prediction and classification. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM0LeeqAPI28aK5TYEN11ah",
   "collapsed_sections": [],
   "name": "Regression_Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
