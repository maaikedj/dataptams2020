{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9l8qyLoGS2z"
   },
   "source": [
    "# Working with APIs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4t8tGqd7Gadp"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Thus far in the program, we have learned how to obtain data from files and from relational databases. However, sometimes the data we need is not readily available via one of these two data sources. In some cases, the data we need may be contained within an application. Application owners will often create APIs **(or Application Programming Interface)** so that their applications can talk to other applications. An **API is a set of programmatic instructions for accessing software applications, and the data that comes from APIs typically contains some sort of structure (such as JSON).** This structure makes working with API data preferable to crawling websites and scraping content off of web pages.\n",
    "\n",
    "In this lesson, we are going to learn how to make API calls to an application, retrieve data in JSON format, learn about API authentication, and use Python libraries to obtain data from APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "waQdrpUTGfh1"
   },
   "source": [
    "## Simple API Example Requests\n",
    "\n",
    "There are a few libraries that can be used for working with APIs in Python, but the Requests library is one of the most intuitive. It has a get method that allows you to send an HTTP request to an application and receive a response. Let's take a look at a basic API call using the requests library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8hSfzOw9GWuX"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://jsonplaceholder.typicode.com/todos')\n",
    "results = response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3iqkvYZNGqez"
   },
   "source": [
    "In this example, we used the get method to send a request to the JSONPlaceholder API, and we received back a response in the form of JSON structured data. If we wanted to analyze this data, we could easily use Pandas to convert the results into a data frame to which we can then apply various analytical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "4zmibc3PGlSj",
    "outputId": "a991db20-936d-4baa-b720-7661bd4a969b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(results)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_6GoybmGtNj"
   },
   "source": [
    "## More Complex API Requests\n",
    "\n",
    "In the previous section, the data we received from the API was not very complex. It was all at a single level and fit neatly into a data frame. However, sometimes API responses contain data that is nested, and we must find a way to **flatten** the JSON data so that it fits nicely into a data frame. To see this, let us make a call to the StackOverflow API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StackAPI\n",
    "from stackapi import StackAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stackapi import StackAPI\n",
    "stack_api = StackAPI('stackoverflow')\n",
    "badges = stack_api.fetch('badges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badges_data = pd.DataFrame(badges)\n",
    "badges_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GithubAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now make an API call to the Github public API, create a Pandas data frame from the results, and examine the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "colab_type": "code",
    "id": "Q0ZZg5M7G2F8",
    "outputId": "b1a035aa-87a1-4157-c128-ab1f2cd846ea"
   },
   "outputs": [],
   "source": [
    "response = requests.get('https://api.github.com/events')\n",
    "\n",
    "data = pd.DataFrame(response.json())\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rL2xpHP9G9lE"
   },
   "source": [
    "When we look at the data frame, we can see that there are dictionaries nested in several fields. We need to extract the information that is in these fields and add them to the data frame as columns. To do this, we are going to create our own flatten function that accepts a data frame and a list of columns that contain nested dictionaries in them. Our function is going to iterate through the columns and, for each column, it is going to:\n",
    "\n",
    "- Turn the nested dictionaries into a data frame with a column for each key\n",
    "- Assign column names to each column in this new data frame\n",
    "- Add these new columns to the original data frame\n",
    "- Drop the column with the nested dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Complex API Requests: One Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the data['actor'] column\n",
    "data['actor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data['actor'] column to a dictionary\n",
    "dict(data['actor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new data frame \n",
    "flatten = pd.DataFrame(dict(data['actor']))\n",
    "flatten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose flatten\n",
    "\n",
    "flatten = pd.DataFrame(dict(data['actor'])).transpose()\n",
    "flatten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the columns as strings\n",
    "\n",
    "columns = [str(i) for i in flatten.columns]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns for actor\n",
    "\n",
    "flatten.columns = ['actor' + '_' + colname for colname in columns]\n",
    "flatten.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add flatten to data using pd.concat\n",
    "\n",
    "data = pd.concat([data, flatten], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the 'messy' column\n",
    "\n",
    "data = data.drop('actor', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Complex API Requests: For Loop \n",
    "\n",
    "Most data types of these kinds have more than one condensed column. In that case, it is useful to simply loop over those columns for which this holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialise the data\n",
    "response = requests.get('https://api.github.com/events')\n",
    "data = pd.DataFrame(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns that contain a dictionary\n",
    "col_list = ['actor', 'org', 'payload', 'repo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A6T2tgWQG3Cj"
   },
   "outputs": [],
   "source": [
    "# Create a for-loop to loop over the columns\n",
    "for column in col_list:\n",
    "    flattened = pd.DataFrame(dict(data[column])).transpose()\n",
    "    columns = [str(col) for col in flattened.columns]\n",
    "    flattened.columns = [column + '_' + colname for colname in columns]\n",
    "    data = pd.concat([data, flattened], axis=1)\n",
    "    data = data.drop(column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Complex API Requests: Function \n",
    "\n",
    "We can also write a function that does this for us. Using a function allows us to return a new data frame without actually interfering upon the original one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialise the data\n",
    "response = requests.get('https://api.github.com/events')\n",
    "data = pd.DataFrame(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(data, col_list):\n",
    "    for column in col_list:\n",
    "        flattened = pd.DataFrame(dict(data[column])).transpose()\n",
    "        columns = [str(col) for col in flattened.columns]\n",
    "        flattened.columns = [column + '_' + colname for colname in columns]\n",
    "        data = pd.concat([data, flattened], axis=1)\n",
    "        data = data.drop(column, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function flatten\n",
    "nested_columns = ['actor', 'org', 'payload', 'repo']\n",
    "\n",
    "flat = flatten(data, nested_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display here\n",
    "flat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Complex API Requests: JSON_Normalise Function  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "daHCvfXgHW5U"
   },
   "source": [
    "Alternatively, we can flatten nested data using the function json_normalize. This function is part of the Pandas library. The function will flatten and rename each flattened column to the name of the original column and the name of the nested column separated by a period. For example actor.avatar_url.\n",
    "\n",
    "Here is an example of how to use this function. Note that you have to import it separately in order to avoid using the full path when calling the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9UZxVwaMHN8Q",
    "outputId": "abcd6f6c-26de-475d-e462-3f76020beca1"
   },
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "\n",
    "results = response.json()\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_data = json_normalize(results)\n",
    "flattened_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EWdMdifhHeXR"
   },
   "source": [
    "This data looks much cleaner, and now we have access to the information that was enclosed within those dictionaries. Sometimes multiple rounds of flattening will be required if the JSON data returned from the API you are working with has hierarchically nested data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QUxB_mA7HgbU"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this lesson, we covered the basics of working with APIs. We began by introducing the requests library and showing how to make a simple API call using it. We then obtained some more complex JSON data from an API, where the information was nested, and learned how to flatten it."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Working_with_Apis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
